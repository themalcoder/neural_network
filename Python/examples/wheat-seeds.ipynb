{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append(\"../src\")  # Adds source directory to python modules path.\n",
    "from nn import neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/wheat-seeds.csv', header=None) # importing without header as csv doesn't have one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data to pass into the Neural Network\n",
    "\n",
    "training_data = df[[i for i in range(len(df.columns) - 1)]]\n",
    "training_data_label = df[len(df.columns) - 1]\n",
    "\n",
    "data_rows = [rows for _, rows in training_data.iterrows()]\n",
    "\n",
    "labels = []\n",
    "for i in training_data_label:\n",
    "    if(i == 1):\n",
    "        labels.append([1, 0, 0])\n",
    "    elif(i == 2):\n",
    "        labels.append([0, 1, 0])\n",
    "    elif(i == 3):\n",
    "        labels.append([0, 0, 1])\n",
    "\n",
    "training = [{'inputs': data_rows[i], 'output': labels[i]} for i in range(len(training_data_label))]\n",
    "\n",
    "# training[0]['outputs']\n",
    "# data = random.choice(training)\n",
    "# data['output']\n"
   ]
  },
  {
   "source": [
    "## CAUTION!!! \n",
    "#### If you already have a saved model for this data, then don't waste you time training it, just load it... \n",
    "\n",
    "#### Otherwise, just uncomment this cell"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network\n",
    "# nn = neural_network(len(rows[0]), 10, 3)\n",
    "# iterations = len(rows) * 1000\n",
    "# print(f'Training NN with {iterations} iterations')\n",
    "# for x in range(iterations):\n",
    "#     # Use random data from the training set in every iteration\n",
    "#     data = random.choice(training)\n",
    "#     # Training with that data\n",
    "#     nn.train(data['inputs'], data['output'])\n",
    "#     # To print the progress every 10%\n",
    "#     if x % (iterations / 10) == 0:\n",
    "#         print((x / (iterations / 10) * 10), '%')\n",
    "\n",
    "#print()\n",
    "# model = nn.save_model('seeds-data') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if alread have a saved model, load it here\n",
    "nn = neural_network(len(data_rows[0]), 10, 3)\n",
    "nn = nn.load_model('seeds-data') # Testing loading of the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\nRunning tests for the test data\n\nSeeds: [12.3, 13.34, 0.8684, 5.243, 2.974, 5.637, 5.063]\nPREDICTION: 3, Actual: 3\n\nSeeds: [18.72, 16.19, 0.8977, 6.006, 3.857, 5.324, 5.879]\nPREDICTION: 2, Actual: 2\n\nSeeds: [16.23, 15.18, 0.885, 5.872, 3.472, 3.769, 5.922]\nPREDICTION: 2, Actual: 2\n\nSeeds: [16.2, 15.27, 0.8734, 5.826, 3.464, 2.823, 5.527]\nPREDICTION: 2, Actual: 1\n\nSeeds: [19.06, 16.45, 0.8854, 6.416, 3.719, 2.248, 6.163]\nPREDICTION: 2, Actual: 2\n\nSeeds: [14.16, 14.4, 0.8584, 5.658, 3.129, 3.072, 5.176]\nPREDICTION: 2, Actual: 1\n\nSeeds: [11.56, 13.31, 0.8198, 5.363, 2.683, 4.062, 5.182]\nPREDICTION: 3, Actual: 3\n\n"
     ]
    }
   ],
   "source": [
    "tests_data = [\n",
    "        [12.3, 13.34, 0.8684, 5.243, 2.974, 5.637, 5.063],\n",
    "        [18.72, 16.19, 0.8977, 6.006, 3.857, 5.324, 5.879], \n",
    "        [16.23, 15.18, 0.885, 5.872, 3.472, 3.769, 5.922], \n",
    "        [16.2, 15.27, 0.8734, 5.826, 3.464, 2.823, 5.527], \n",
    "        [19.06, 16.45, 0.8854, 6.416, 3.719, 2.248, 6.163], \n",
    "        [14.16, 14.4, 0.8584, 5.658, 3.129, 3.072, 5.176], \n",
    "        [11.56, 13.31, 0.8198, 5.363, 2.683, 4.062, 5.182]\n",
    "    ]\n",
    "test_labels = [3, 2, 2, 1, 2, 1, 3]\n",
    "print()\n",
    "print()\n",
    "\n",
    "# nn = nn.load_model('xor-data') # Testing loading of the pre-trained model\n",
    "print(\"Running tests for the test data\")\n",
    "print('')\n",
    "i = 0\n",
    "for test in tests_data:\n",
    "    # Get the NN prediction of each input\n",
    "    prediction = nn.predict(test)\n",
    "    max_pred_value = np.max(prediction)\n",
    "    max_pred_index = np.where(prediction == max_pred_value)[0][0] + 1\n",
    "    # Print the results\n",
    "    print(f'Seeds: {test}')\n",
    "    print(f'PREDICTION: {max_pred_index}, Actual: {test_labels[i]}')\n",
    "    # print(f'MAX PREDICTION: {max_pred_index}')\n",
    "    # print(f'PRECISION: {prediction}')\n",
    "    i += 1\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}